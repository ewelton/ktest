created:1578148369751
modified:1578148369751
title:Fairness and Abstraction in Sociotechnical Systems
type:text/vnd.tiddlywiki
audience:
author(s)editor(s):
date:
digital.harms.addressed:
element.type:publication
github.profile:
input.source:me2b
jurisdiction:
license:
name:Fairness and Abstraction in Sociotechnical Systems
publication.type:to-be-determined
purpose:
sector:
sponsoring.org:
tags:[[ai on the ground]] [[acm conference on fairness]] [[accountability]] [[and transparency]]
tech.focus:
tmap.edges:{}
tmap.id:cd7b8dda-2ca3-413a-9794-6aec2779861c
url:
version.or.edition:
volume.frequency:
working.group:

In this paper, authors identify the challenges to integrating fairness into machine learning based systems and suggest next steps.

    “In this paper, however, we contend that these concepts render technical interventions ineffective, inaccurate, and sometimes dangerously misguided when they enter the societal context that surrounds decision-making systems. We outline this mismatch with five “traps” that fair-ML work can fall into even as it attempts to be more context-aware in comparison to traditional data science. We draw on studies of sociotechnical systems in Science and Technology Studies to explain why such traps occur and how to avoid them. Finally, we suggest ways in which technical designers can mitigate the traps through a refocusing of design in terms of process rather than solutions, and by drawing abstraction boundaries to include social actors rather than purely technical ones.”



## FROM THE PROPOSAL 

identify what products and services are being provided by catalyst and support organizations working on privacy related iniatitives. 



interdependencies between Me2B and external organizations:  what Me2B Alliance gives to and what it receives from a particular organization.


connections with the right people and orgs in order to leverage and/or support specific products/services.


understand what organizations are working on particular aspects of promoting digital privacy, dignity and empowerment.  

 Trustable Technology enabler organizations are currently defined as follows but these should be vetted and validated in developing the final ontology: 

* Movements (Education, PR, Awareness)
* Standards Bodies
* Open Source Implementations
* Consumer  Organizations
* Trade Organizations 
* Certifications
* Policy & Regulatory
* Thinktanks
* Academic & Research


## From LISA's e-mails
would be good to be able to filter on “Organization Principles”.  This seems hard and maybe not possible, but as I clarify how Me2B has a slightly different orientation than other orgs, it’s important to understand the “venn diagram” of how orgs share and differentiate based on principles

biomedical and patient rights type orgs 


I’d like to start creating a list of reailstic search requests we might actually be interested in (and I will even reach out to the Me2B community and maybe VRM list).  Here are some for me—please add yours:
 
Which organizations are working on:
 
* Certification
* Terms of Service
* Legal
* Privacy Rights
* Legal Duties of businesses
* Individual privacy rights
* FIPs
* FIPPS
* Data use permissions
* Privacy usability
* Security privacy ux  dissonance
* Data right to use
* Reverse eula
* SSI usability


became clear that there is a relationship between individual harms/violations listed in the dictionary and organizations working on those harms.  For instance, Me2B will *not* be covering all of the harms listed in the dictionary.  Good examples are that the Center for Humane Society is covering some of the bigger more individual-behavioral type harms, and Kathryn Harrison’s “Deep Trust Alliance” is working on Deep Fakes, for example.  So we’d want to indicate in the Harms Dictionary for each entry which orgs are working on mitigating those harms.  (Possibly.) 